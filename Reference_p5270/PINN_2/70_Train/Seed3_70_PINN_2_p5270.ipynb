{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-roZvPr9GXTe"
      },
      "source": [
        "# Load Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution() # 移除此行以启用 Eager Execution\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.python.keras.layers import Lambda\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from keras.layers import Dense, LSTM, TimeDistributed, Flatten, Bidirectional, Input\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import h5py\n",
        "import math\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import files\n",
        "from numpy import savetxt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "np.random.seed(20)\n",
        "tf.random.set_seed(20)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pseuj3KAKUIV",
        "outputId": "9da97edb-5e5b-44e6-c707-c7e09a1ad900"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TR_sCVYw7qR"
      },
      "source": [
        "# Function: Create Data History\n",
        "def create_timesteps(data, n_steps):\n",
        "\tx = []\n",
        "\ty = []\n",
        "\tfor i in range(len(data)-1):\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\tif end_ix > len(data)-1:\n",
        "\t\t\tbreak\n",
        "\t\tx1, y1 = data[i:end_ix, :-1], data[end_ix, -1]\n",
        "\t\tx.append(x1)\n",
        "\t\ty.append(y1)\n",
        "\treturn np.array(x), np.array(y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data1 = loadmat('/content/drive/My Drive/Colab Notebooks/PINN_Paper_Codes/New_Models/Reference_p5270/Data/p5270_Data.mat')\n",
        "data2 = loadmat('/content/drive/My Drive/Colab Notebooks/PINN_Paper_Codes/New_Models/Reference_p5270/Data/p5270MechData.mat')\n",
        "a_t = pd.DataFrame({'Time':data1['LocalAcTime'].ravel().round(2), 'freqQAmpI_filt':data1['freqQAmpI_filt'].ravel(),'physics_out':data1['physics_out'].ravel()})\n",
        "w_t = pd.DataFrame({'Time':data1['LocalAcTime'].ravel().round(2),'C_filt':data1['C_filt'].ravel()})\n",
        "m_t = pd.DataFrame({'Time':data1['Time'].ravel().round(2), 'SS':data1['SS'].ravel()})\n",
        "s_t = pd.DataFrame({'Time':data2['Time'].ravel().round(2), 'V':data2['V'].ravel(), 'V_filt':data2['V_filt'].ravel()})\n",
        "df = a_t.merge(w_t, on='Time')\n",
        "df = df.merge(m_t, on='Time')\n",
        "df = df.merge(s_t, on='Time')\n",
        "df = df[['freqQAmpI_filt', 'C_filt','V_filt','Time','V','SS','physics_out']]\n",
        "df_SS = df[['freqQAmpI_filt', 'C_filt', 'SS']]\n",
        "df_V = df[['freqQAmpI_filt', 'C_filt', 'V_filt']]\n",
        "df_PhyOut = df[['freqQAmpI_filt', 'C_filt', 'physics_out']]\n",
        "df_A = df_A = df[['freqQAmpI_filt','C_filt','freqQAmpI_filt']]\n",
        "df_WV = df[['freqQAmpI_filt','C_filt','C_filt']]\n",
        "xdf = df[['freqQAmpI_filt', 'C_filt']]\n",
        "ydf = df[['SS','V_filt']]\n",
        "print(\"Input Data:\\n\", xdf)\n",
        "print(\"Target Data:\\n\",ydf)"
      ],
      "metadata": {
        "id": "psStM3Fhrd0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4182fc6-1feb-411e-91a8-f3f156ca98c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data:\n",
            "         freqQAmpI_filt       C_filt\n",
            "0         31453.223522  5490.232850\n",
            "1         31438.277060  5490.239343\n",
            "2         31421.341616  5490.240838\n",
            "3         31409.798761  5490.232728\n",
            "4         31398.815589  5490.222463\n",
            "...                ...          ...\n",
            "132394    31055.686766  5457.051859\n",
            "132395    31041.955345  5457.082380\n",
            "132396    31035.059531  5457.111463\n",
            "132397    31020.001291  5457.126443\n",
            "132398    31012.016780  5457.151945\n",
            "\n",
            "[132399 rows x 2 columns]\n",
            "Target Data:\n",
            "               SS    V_filt\n",
            "0       5.656166  1.201004\n",
            "1       5.657157  1.243144\n",
            "2       5.658317  1.264215\n",
            "3       5.659499  1.243144\n",
            "4       5.660404  1.222074\n",
            "...          ...       ...\n",
            "132394  5.471059  1.285285\n",
            "132395  5.474545  0.948161\n",
            "132396  5.478286  1.158863\n",
            "132397  5.481751  1.201004\n",
            "132398  5.484813  0.526756\n",
            "\n",
            "[132399 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPls_CKexIXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07e03c9-df1b-46f9-a96c-87c0be77ffa8"
      },
      "source": [
        "# Preprocessing (SS)\n",
        "arr = df_SS.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, ydf_SS = create_timesteps(arr, n_steps)\n",
        "\n",
        "# Preprocessing (V)\n",
        "arr = df_V.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, ydf_V = create_timesteps(arr, n_steps)\n",
        "\n",
        "# Preprocessing (Physics_Out)\n",
        "arr = df_PhyOut.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, phy_outdf = create_timesteps(arr, n_steps)\n",
        "\n",
        "# Preprocessing (A)\n",
        "arr = df_A.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, Adf = create_timesteps(arr, n_steps)\n",
        "\n",
        "# Preprocessing (WV)\n",
        "arr = df_WV.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, WVdf = create_timesteps(arr, n_steps)\n",
        "\n",
        "print('Features shape, X = ', np.shape(xdf))\n",
        "print('Target shape (SS), Y = ', np.shape(ydf_SS))\n",
        "print('Target shape (V), Y = ', np.shape(ydf_V))\n",
        "print('Target shape (A), Y = ', np.shape(Adf))\n",
        "print('Target shape (WV), Y = ', np.shape(WVdf))\n",
        "print('Target shape (Physics_Out), Y = ', np.shape(phy_outdf))\n",
        "\n",
        "# Reshape\n",
        "in_dim = xdf.shape[1]*xdf.shape[2]\n",
        "xdf = xdf.reshape((xdf.shape[0], in_dim))\n",
        "print('After reshaping, X = ', np.shape(xdf))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape, X =  (132099, 300, 2)\n",
            "Target shape (SS), Y =  (132099,)\n",
            "Target shape (V), Y =  (132099,)\n",
            "Target shape (A), Y =  (132099,)\n",
            "Target shape (WV), Y =  (132099,)\n",
            "Target shape (Physics_Out), Y =  (132099,)\n",
            "After reshaping, X =  (132099, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpYHvGS50B6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d791b4-229e-4ef8-9b5b-6cc1f11de542"
      },
      "source": [
        "# Split into train-val-test (SS)\n",
        "x_train, x_test, y_train_SS, y_test_SS = train_test_split(xdf, ydf_SS, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train_SS, Y_val_SS = train_test_split(x_train, y_train_SS, test_size=0.125, shuffle=False)\n",
        "\n",
        "# Split into train-val-test (V)\n",
        "x_train, x_test, y_train_V, y_test_V = train_test_split(xdf, ydf_V, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train_V, Y_val_V = train_test_split(x_train, y_train_V, test_size=0.125, shuffle=False)\n",
        "\n",
        "# Split into train-val-test (A)\n",
        "x_train, x_test, y_train_A, y_test_A = train_test_split(xdf, Adf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train_A, Y_val_A = train_test_split(x_train, y_train_A, test_size=0.125, shuffle=False)\n",
        "\n",
        "# Split into train-val-test (WV)\n",
        "x_train, x_test, y_train_WV, y_test_WV = train_test_split(xdf, WVdf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train_WV, Y_val_WV = train_test_split(x_train, y_train_WV, test_size=0.125, shuffle=False)\n",
        "\n",
        "# Split into train-val-test (Physics Out)\n",
        "x_train, x_test, y_train_Phy, y_test_Phy = train_test_split(xdf, phy_outdf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train_Phy, Y_val_Phy = train_test_split(x_train, y_train_Phy, test_size=0.125, shuffle=False)\n",
        "\n",
        "# Select Train\n",
        "X_train = X_train[0:92469]\n",
        "Y_train_SS = Y_train_SS[0:92469]\n",
        "Y_train_V = Y_train_V[0:92469]\n",
        "Y_train_Phy = Y_train_Phy[0:92469]\n",
        "Y_train_A = Y_train_A[0:92469]\n",
        "Y_train_WV = Y_train_WV[0:92469]\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "X_val = pd.DataFrame(scaler.transform(X_val))\n",
        "x_test = pd.DataFrame(scaler.transform(x_test))\n",
        "\n",
        "print(\"Training samples:\", np.shape(X_train)[0])\n",
        "print(\"Validation samples:\", np.shape(X_val)[0])\n",
        "print(\"Testing samples:\", np.shape(x_test)[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 92469\n",
            "Validation samples: 13210\n",
            "Testing samples: 26420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the output: SS\n",
        "scaler_ss = MinMaxScaler()\n",
        "Y_train_SS = pd.DataFrame(scaler_ss.fit_transform(Y_train_SS.reshape(-1, 1)))\n",
        "Y_val_SS = pd.DataFrame(scaler_ss.transform(Y_val_SS.reshape(-1, 1)))\n",
        "y_test_SS = pd.DataFrame(scaler_ss.transform(y_test_SS.reshape(-1, 1)))"
      ],
      "metadata": {
        "id": "BtdAEK4_B0QH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the output: V\n",
        "scaler_v = MinMaxScaler()\n",
        "Y_train_V = pd.DataFrame(scaler_v.fit_transform(Y_train_V.reshape(-1, 1)))\n",
        "Y_val_V = pd.DataFrame(scaler_v.transform(Y_val_V.reshape(-1, 1)))\n",
        "y_test_V = pd.DataFrame(scaler_v.transform(y_test_V.reshape(-1, 1)))"
      ],
      "metadata": {
        "id": "Ang7hmuZEP-Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize WV\n",
        "scaler_wv = MinMaxScaler()\n",
        "Y_train_WV = pd.DataFrame(scaler_wv.fit_transform(Y_train_WV.reshape(-1, 1)))\n",
        "Y_val_WV = pd.DataFrame(scaler_wv.transform(Y_val_WV.reshape(-1, 1)))\n",
        "y_test_WV = pd.DataFrame(scaler_wv.transform(y_test_WV.reshape(-1, 1)))"
      ],
      "metadata": {
        "id": "0I0GDPCkGdKW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Amp\n",
        "scaler_A = MinMaxScaler()\n",
        "Y_train_A = pd.DataFrame(scaler_A.fit_transform(Y_train_A.reshape(-1, 1)))\n",
        "Y_val_A = pd.DataFrame(scaler_A.transform(Y_val_A.reshape(-1, 1)))\n",
        "y_test_A = pd.DataFrame(scaler_A.transform(y_test_A.reshape(-1, 1)))"
      ],
      "metadata": {
        "id": "-0TLsN9nWRbj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time derivative function\n",
        "# The original global variable `ss1` caused issues in TensorFlow graph mode (tf.compat.v1.disable_eager_execution).\n",
        "# This function is now stateless and returns a compatible tensor to avoid graph construction errors.\n",
        "# If an actual non-zero time derivative is needed, it must be computed in a graph-compatible way,\n",
        "# for example, by providing the previous state as an input to the layer or using tf.gradients\n",
        "# with an explicit time variable.\n",
        "def Time_Derivative(del_t, ss2):\n",
        "    # Returning a tensor compatible with ss2 to unblock the compilation error.\n",
        "    # This assumes that for the physics constraint, the derivative term can be considered zero,\n",
        "    # or serves as a placeholder to fix graph construction.\n",
        "    return tf.zeros_like(ss2)"
      ],
      "metadata": {
        "id": "jzzuaqLk767v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0wOIa-_1l1z"
      },
      "source": [
        "**Define Physics-Informed Model**: **Self Learning Constants**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Physics\n",
        "class gradient_1(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(gradient_1,self).__init__()\n",
        "    self.SS = tf.keras.layers.Dense(1)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    self.A = tf.keras.layers.Dense(1)\n",
        "    self.WV = tf.keras.layers.Dense(1)\n",
        "    self.all_scale = tf.keras.layers.Dense(1)\n",
        "    # Weights will be added in build method\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.c1 = self.add_weight(name=\"c1\", shape=(1,), trainable=True)\n",
        "    self.c2 = self.add_weight(name=\"c2\", shape=(1,), trainable=True)\n",
        "    self.c3 = self.add_weight(name=\"c3\", shape=(1,), trainable=True)\n",
        "    self.c4 = self.add_weight(name=\"c4\", shape=(1,), trainable=True)\n",
        "    initializer = tf.keras.initializers.RandomUniform(10000,30000)\n",
        "    self.c5 = self.add_weight(name=\"c5\", shape=(1,), initializer = initializer,trainable=True)\n",
        "    super(gradient_1, self).build(input_shape) # Important to call super().build()\n",
        "\n",
        "  def call(self, params):\n",
        "    ss_pred, v_pred, Amp, wv = params\n",
        "    ss_pred = self.SS(ss_pred)\n",
        "    v_pred = self.V(v_pred)\n",
        "    Amp = self.A(Amp)\n",
        "    wv = self.WV(wv)\n",
        "\n",
        "    term1 = Time_Derivative(0.01,ss_pred)\n",
        "    term2 = tf.divide(self.c2*Amp*self.c3*0.4*tf.constant(math.pi)*wv,self.c5)\n",
        "    term3 = self.c2*(tf.math.sqrt((1-(tf.divide(Amp,(self.c5)))**2)))\n",
        "    term4 = tf.divide(tf.constant(math.pi)*Amp*self.c3*0.4*wv,self.c5)\n",
        "    term5 = term3+term4\n",
        "    term6 = (self.c4-v_pred)\n",
        "    term7 = tf.divide(1.,self.c1) # Using 1.0 to ensure float division\n",
        "    term8 = tf.divide(term2,term5)\n",
        "    term9 = tf.multiply(term8,term6)\n",
        "    term10 = tf.multiply(term1,term7)\n",
        "    eqn = term10-term9\n",
        "    eqn = self.all_scale(eqn)\n",
        "\n",
        "    return eqn"
      ],
      "metadata": {
        "id": "lQVJgcu53TFR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFHn6O9Z1sl-"
      },
      "source": [
        "# Define PINN\n",
        "def MLP_Physics():\n",
        "\n",
        "  # Define inputs\n",
        "  X_train = layers.Input(shape=(600,),name='X_train')\n",
        "  Amp =layers.Input(shape=(1,),name='Amp')\n",
        "  wv =layers.Input(shape=(1,),name='wv')\n",
        "\n",
        "  # Prediction: Shear Stress + Slip Rate\n",
        "  x = layers.Dense(128,kernel_initializer = 'normal', activation=\"relu\")(X_train)\n",
        "  x = layers.Dense(64,kernel_initializer = 'normal', activation=\"relu\")(x)\n",
        "  x = layers.Dense(32,kernel_initializer = 'normal', activation=\"relu\")(x)\n",
        "  x = layers.Dense(16, kernel_initializer = 'normal', activation=\"relu\")(x)\n",
        "  x = layers.Dense(8, kernel_initializer = 'normal', activation=\"relu\")(x)\n",
        "  ss_pred = layers.Dense(1,kernel_initializer = 'normal',activation=\"linear\")(x)\n",
        "  v_pred = layers.Dense(1,kernel_initializer = 'normal',activation=\"linear\")(x)\n",
        "\n",
        "  # Model\n",
        "  grad_out = gradient_1()([ss_pred,v_pred,Amp,wv])\n",
        "  model = keras.Model(inputs=[X_train,Amp,wv],outputs=[ss_pred,v_pred,grad_out])\n",
        "  return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYvDGpmucDtY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "95b69d4e-beee-4764-f8af-a2510d116e8b"
      },
      "source": [
        "# Model Summary\n",
        "model=MLP_Physics()\n",
        "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=['mse','mse'])\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Exception encountered when calling gradient_1.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'gradient_1_1' (of type gradient_1). Either the `gradient_1.call()` method is incorrect, or you need to implement the `gradient_1.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\n'str' object has no attribute 'base_dtype'\u001b[0m\n\nArguments received by gradient_1.call():\n  • args=(['<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=keras_tensor_12>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=keras_tensor_13>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=Amp>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=wv>'],)\n  • kwargs=<class 'inspect._empty'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-926366649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model Summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLP_Physics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3472898140.py\u001b[0m in \u001b[0;36mMLP_Physics\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mgrad_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mss_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mss_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2162222533.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mterm5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mterm4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mterm6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc4\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mv_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mterm7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Using 1.0 to ensure float division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mterm8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mterm9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling gradient_1.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'gradient_1_1' (of type gradient_1). Either the `gradient_1.call()` method is incorrect, or you need to implement the `gradient_1.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\n'str' object has no attribute 'base_dtype'\u001b[0m\n\nArguments received by gradient_1.call():\n  • args=(['<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=keras_tensor_12>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=keras_tensor_13>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=Amp>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=wv>'],)\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WMyqaVd6xn4"
      },
      "source": [
        "# Train The Model\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=20,verbose=1, mode='auto')\n",
        "callbacks_list = [earlystop]\n",
        "start_time = time.time()\n",
        "history = model.fit([X_train,Y_train_A,Y_train_WV],[Y_train_SS,Y_train_V,Y_train_Phy], epochs=100, batch_size=32,callbacks=callbacks_list,\n",
        "                     validation_data=([X_val,Y_val_A,Y_val_WV],[Y_val_SS,Y_val_V,Y_val_Phy]), verbose=1)\n",
        "end_time = time.time()\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"---Training time: %0.8f seconds ---\" % (end_time - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the model\n",
        "# print(model.summary())\n",
        "# model.save('/content/drive/My Drive/Colab Notebooks/PINN_Paper_Codes/Reference_p5270/PINN_2/Exact_PINN_Transfer_model_70_10_20.h5')"
      ],
      "metadata": {
        "id": "2uiygDevskrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExjCb1JGgprm"
      },
      "source": [
        "# Model Performance: Training\n",
        "y_predtrain = model.predict([X_train,Y_train_A,Y_train_WV])\n",
        "y_predtrain_SS = np.array(y_predtrain)[0,]\n",
        "y_predtrain_V =np.array(y_predtrain)[1,]\n",
        "\n",
        "train_r2_SS = r2_score(Y_train_SS, y_predtrain_SS)\n",
        "train_rmse_SS = np.sqrt(mean_squared_error(Y_train_SS, y_predtrain_SS))\n",
        "\n",
        "train_r2_V = r2_score(Y_train_V,y_predtrain_V)\n",
        "train_rmse_V = np.sqrt(mean_squared_error(Y_train_V, y_predtrain_V ))\n",
        "\n",
        "# Model Performance: Validation\n",
        "y_predval = model.predict([X_val,Y_val_A,Y_val_WV])\n",
        "y_predval_SS = np.array(y_predval)[0,]\n",
        "y_predval_V = np.array(y_predval)[1,]\n",
        "\n",
        "val_r2_SS = r2_score(Y_val_SS, y_predval_SS)\n",
        "val_rmse_SS = np.sqrt(mean_squared_error(Y_val_SS, y_predval_SS))\n",
        "\n",
        "val_r2_V = r2_score(Y_val_V, y_predval_V)\n",
        "val_rmse_V = np.sqrt(mean_squared_error(Y_val_V, y_predval_V))\n",
        "\n",
        "# Model Performance: Testing\n",
        "y_predtest = model.predict([x_test,y_test_A,y_test_WV])\n",
        "y_predtest_SS =np.array(y_predtest)[0,]\n",
        "y_predtest_V = np.array(y_predtest)[1,]\n",
        "\n",
        "test_r2_SS = r2_score(y_test_SS,y_predtest_SS)\n",
        "test_rmse_SS = np.sqrt(mean_squared_error(y_test_SS, y_predtest_SS))\n",
        "\n",
        "test_r2_V = r2_score(y_test_V,y_predtest_V)\n",
        "test_rmse_V = np.sqrt(mean_squared_error(y_test_V, y_predtest_V))\n",
        "\n",
        "# Print R2 Results\n",
        "print(\"R2 scores: Train (SS) - %0.5f, Train (V) - %0.5f\" %(train_r2_SS , train_r2_V))\n",
        "print(\"R2 scores: Validation (SS) - %0.5f, Validation (V) - %0.5f\" %(val_r2_SS , val_r2_V))\n",
        "print(\"R2 scores: Testing (SS) - %0.5f, Testing (V) - %0.5f\" %(test_r2_SS , test_r2_V))\n",
        "\n",
        "# Print RSME Results\n",
        "print(\"RMSE scores: Train (SS) - %0.5f, Train (V) - %0.5f\" %(train_rmse_SS , train_rmse_V))\n",
        "print(\"RMSE scores: Validation (SS) - %0.5f, Validation (V) - %0.5f\" %(val_rmse_SS , val_rmse_V))\n",
        "print(\"RMSE scores: Testing (SS) - %0.5f, Testing (V) - %0.5f\" %(test_rmse_SS , test_rmse_V))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling: SS\n",
        "Y_train_SS = scaler_ss.inverse_transform(Y_train_SS)\n",
        "Y_val_SS = scaler_ss.inverse_transform(Y_val_SS)\n",
        "y_test_SS = scaler_ss.inverse_transform(y_test_SS)\n",
        "y_predtrain_SS = scaler_ss.inverse_transform(y_predtrain_SS)\n",
        "y_predval_SS = scaler_ss.inverse_transform(y_predval_SS)\n",
        "y_predtest_SS = scaler_ss.inverse_transform(y_predtest_SS)"
      ],
      "metadata": {
        "id": "b3dnB8y3JKvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling: V\n",
        "Y_train_V = scaler_v.inverse_transform(Y_train_V)\n",
        "Y_val_V = scaler_v.inverse_transform(Y_val_V)\n",
        "y_test_V = scaler_v.inverse_transform(y_test_V)\n",
        "y_predtrain_V = scaler_v.inverse_transform(y_predtrain_V)\n",
        "y_predval_V = scaler_v.inverse_transform(y_predval_V)\n",
        "y_predtest_V = scaler_v.inverse_transform(y_predtest_V)"
      ],
      "metadata": {
        "id": "2R6aulZ1JMgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoPgcsgI-spY"
      },
      "source": [
        "# Overall plot: SS & V\n",
        "ttime = df['Time'][n_steps:]\n",
        "t1, testtime = train_test_split(ttime, test_size=0.2, shuffle=False)\n",
        "traintime, valtime = train_test_split(t1, test_size=0.125, shuffle=False)\n",
        "\n",
        "traintime = traintime[0:92469]\n",
        "\n",
        "fig = plt.figure(1, figsize=(20,6))\n",
        "plt.plot(ttime, ydf_SS)\n",
        "plt.plot(traintime, y_predtrain_SS)\n",
        "plt.plot(valtime, y_predval_SS)\n",
        "plt.plot(testtime, y_predtest_SS)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Shear Stress (MPa)')\n",
        "plt.legend(['Ground truth', 'Train Prediction', 'Validation Prediction', 'Test Prediction'])\n",
        "\n",
        "fig = plt.figure(2, figsize=(20,6))\n",
        "plt.plot(ttime, ydf_V)\n",
        "plt.plot(traintime, y_predtrain_V)\n",
        "plt.plot(valtime,  y_predval_V)\n",
        "plt.plot(testtime, y_predtest_V)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Slip Rate (um/s)')\n",
        "plt.legend(['Ground truth', 'Train Prediction', 'Validation Prediction', 'Test Prediction'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOh64b1lB1Nv"
      },
      "source": [
        "# Individual plot: SS\n",
        "\n",
        "def results_plot(fig_no, t, gt, pred, title, col):\n",
        "  fig = plt.figure(fig_no, figsize=(20,6))\n",
        "  plt.plot(t, gt)\n",
        "  plt.plot(t, pred, col)\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.ylabel('Shear Stress (MPa)')\n",
        "  plt.legend(['Ground truth', 'Predicted'])\n",
        "  plt.title(title)\n",
        "\n",
        "results_plot(1, traintime, Y_train_SS, y_predtrain_SS, 'Training data', '')\n",
        "results_plot(2, valtime, Y_val_SS, y_predval_SS, 'Validation data', 'g')\n",
        "results_plot(3, testtime, y_test_SS, y_predtest_SS, 'Testing data', 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXEr3tihCWuw"
      },
      "source": [
        "# Individual plot: V\n",
        "\n",
        "def results_plot(fig_no, t, gt, pred, title, col):\n",
        "  fig = plt.figure(fig_no, figsize=(20,6))\n",
        "  plt.plot(t, gt)\n",
        "  plt.plot(t, pred, col)\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.ylabel('Slip Rate (um/s)')\n",
        "  plt.legend(['Ground truth', 'Predicted'])\n",
        "  plt.title(title)\n",
        "\n",
        "results_plot(1, traintime, Y_train_V, y_predtrain_V, 'Training data', '')\n",
        "results_plot(2, valtime, Y_val_V, y_predval_V, 'Validation data', 'g')\n",
        "results_plot(3, testtime, y_test_V, y_predtest_V, 'Testing data', 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Weights\n",
        "names = [weight.name for layer in model.layers for weight in layer.weights]\n",
        "weights = model.get_weights()\n",
        "\n",
        "for name, weight in zip(names, weights):\n",
        "    print(name, weight.shape)"
      ],
      "metadata": {
        "id": "8t80ZP-2qcll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Weights\n",
        "model.get_weights()"
      ],
      "metadata": {
        "id": "dTEKIy_JpIu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Learned Constants\n",
        "\n",
        "# Normal Stress\n",
        "r1 = 10/5.89\n",
        "cols = ['NS']\n",
        "data = pd.DataFrame(np.array([[-1.63]]),columns=cols)\n",
        "NS = scaler_ss.inverse_transform(data)\n",
        "NS = NS*r1\n",
        "\n",
        "# Shear Loading Velocity\n",
        "dt = 0.01\n",
        "cols = ['VL']\n",
        "data = pd.DataFrame(np.array([[1.07]]),columns=cols)\n",
        "VL = scaler_v.inverse_transform(data)\n",
        "VL = (VL*dt)*(2*r1)\n",
        "\n",
        "# Loading Stiffness\n",
        "K = ((2.1)/10)/(3*r1)\n",
        "\n",
        "# Density (kg/cm3)\n",
        "rho = (1.42*10*1000)/(3*r1)\n",
        "\n",
        "print(\"Normal Stress:\",NS)\n",
        "print(\"Shear Loading Velocity:\",VL)\n",
        "print(\"Loading Stiffness:\",K)\n",
        "print(\"Density:\",rho)\n",
        "print(\"A_Intact:\",12745)"
      ],
      "metadata": {
        "id": "9aOxcpi_kpyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract Data\n",
        "\n",
        "# # Time\n",
        "# savetxt('Whole_time.csv', ttime, delimiter=',')\n",
        "# savetxt('traintime.csv', traintime, delimiter=',')\n",
        "# savetxt('valtime.csv', valtime, delimiter=',')\n",
        "# savetxt('testtime.csv', testtime, delimiter=',')\n",
        "\n",
        "# # SS\n",
        "# savetxt('Y_train_SS.csv', Y_train_SS, delimiter=',')\n",
        "# savetxt('Y_val_SS.csv', Y_val_SS, delimiter=',')\n",
        "# savetxt('y_test_SS.csv', y_test_SS, delimiter=',')\n",
        "# savetxt('y_predtrain_SS.csv', y_predtrain_SS, delimiter=',')\n",
        "# savetxt('y_predval_SS.csv', y_predval_SS, delimiter=',')\n",
        "# savetxt('y_predtest_SS.csv', y_predtest_SS, delimiter=',')\n",
        "\n",
        "# # V\n",
        "# savetxt('Y_train_V.csv', Y_train_V, delimiter=',')\n",
        "# savetxt('Y_val_V.csv', Y_val_V, delimiter=',')\n",
        "# savetxt('y_test_V.csv', y_test_V, delimiter=',')\n",
        "# savetxt('y_predtrain_V.csv', y_predtrain_V, delimiter=',')\n",
        "# savetxt('y_predval_V.csv', y_predval_V, delimiter=',')\n",
        "# savetxt('y_predtest_V.csv', y_predtest_V, delimiter=',')\n",
        "\n",
        "# # Download\n",
        "# files.download('Whole_time.csv')\n",
        "# files.download('traintime.csv')\n",
        "# files.download('valtime.csv')\n",
        "# files.download('testtime.csv')\n",
        "\n",
        "# files.download('Y_train_SS.csv')\n",
        "# files.download('Y_val_SS.csv')\n",
        "# files.download('y_test_SS.csv')\n",
        "# files.download('y_predtrain_SS.csv')\n",
        "# files.download('y_predval_SS.csv')\n",
        "# files.download('y_predtest_SS.csv')\n",
        "\n",
        "# files.download('Y_train_V.csv')\n",
        "# files.download('Y_val_V.csv')\n",
        "# files.download('y_test_V.csv')\n",
        "# files.download('y_predtrain_V.csv')\n",
        "# files.download('y_predval_V.csv')\n",
        "# files.download('y_predtest_V.csv')"
      ],
      "metadata": {
        "id": "snZiAHcvyf2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}